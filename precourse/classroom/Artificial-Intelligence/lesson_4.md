# AI 4강 : Deep Learning


### 머신러닝을 위한 3가지
1. 입력 데이터
2. 예상 출력값
3. 알고리즘 정확도 측정법 == 학습
    - 실제 결과와 예상 결과 사이의 차이를 측정
    - 알고리즘 작동 방식을 조정하는 피드백 신호


### 머신러닝과 딥러닝의 공통 목표
> 데이터를 의미 있는 것으로 변환한다.

예상하는 결과에 더 가깝게 접근할 수 있는 **입력 데이터의 유용한 __표현__**을 학습한다.

- 표현?
    + 데이터를 대표하게 하거나, 데이터를 부호화 하기 위해 **데이터를 색다르게 살펴보는 방법**
    + 예) 컬러이미지를 RGB형식 또는 HSV형식으로 부호화하는 작업
- 학습?
    + 더 나은 표현을 자동으로 찾아내는 과정

### 머신러닝 모델
입력 데이터에 대한 적절한 표현을 찾는 모델로, 분류 작업과 같이 현재 직면하고 있는 작업에 **더 적합한 데이터 변환 방식**을 찾는 일이다.

- 예) 딥러닝

### 딥러닝
머신러닝의 특정 하위 분야로, 표현들을 더 의미있게 만들어가는 연속 계층을 학습하게 하는데 중점을 두는 데이터 표현 학습방법.  
시각, 청각 등 지각 문제에 효과적으로 작동한다.

- 딥러닝을 DNN으로 표현하기도 하는데, 이는 Deep Neural Network 의 약자다.
- 인공 신경망이라고도 한다. 신경 생물학에서 차용한 용어로, 딥러닝의 중심 개념은 뇌의 원리와 연관된다.
    + 신경의 전달과정
        1. 뉴런은 네트워크를 형성한다
        2. 여러 뉴런에 전달되는 전기적 신호의 합이 임곗값을 넘으면 뉴런이 반응한다
        3. 반응한 뉴런은 다른 뉴런에 일정 강도의 신호를 전달한다
        - 이 때, 뉴런에 전달되는 신호의 합은 신호마다 **가중치가 다르다**
    + 이처럼, 뇌를 형성하는 뉴런의 집합체를 수학 모델로 나타내는 것이 신경망의 출발이다.
    + 수학적으로 추상화한 신경망을 연속되게 구조화한 방식은 딥러닝이다.

### 딥러닝의 학습
1. 입력데이터는 계층에 의해 데이터변환된 후 (데이터가 특정화 된다고 한다.)
2. **계층의 가중치**라는 형태로 저장된다.
    - 가중치
        + `w`라고 표현하며, 본질적으로 여러 숫자다.
3. 1~2의 과정을 반복한다. 이를 학습이라고 한다.
    - 학습의 목표
        1. 신경망에서 모든 계층의 가중치에 대한 값 집합을 찾는다.
        2. 새 입력값이 목표값에 올바르게 사상할 수 있도록 가중치를 조절하는 작업
            - 도대체 사상이 뭐길래 행렬에서도 여기서도 사상타령일까? 사건 event정도로 이해했는데 다른 의미도 있는듯

### 딥러닝에서의 비용 : 손실함수
은닉층이 여럿일 수 있고, 한 가중치는 다른 가중치에도 영향을 주기 때문에 모든 가중치를 정확하게 알아내는것은 어렵다.  
이를 위해 거리점수를 측정하며, 이를 `손실함수 loss function`라고 말한다.  
손실이 최소화된 신경망은 우리가 원하는 값에 가장 근접한 출력을 낼 수 있다.  

> 손실이 최소인 신경망 == 가장 잘 훈련된 신경망

- 손실함수, 목적함수, 비용함수는 대개 같은 의미로 사용된다. (구체적 차이는 나중에)
- 거리점수
    1. 정의 : 실제 결과값과 신경망이 예측한 결과를 가지고 손실함수가 계산한 값
    2. 목적 : 신경망이 얼마나 적합한지 계산한다.
    3. 활용 : 피드백 신호로 사용하며, 현재 상태의 손실점수를 낮추는 방향으로 가중치를 조정한다. -> 이 때 사용하는 알고리즘이 역전파 알고리즘 이다.
        + 역전파 알고리즘 : (추후 보충) 신경망의 손실점수를 낮추는 알고리즘

### 딥러닝의 성과
- 2012 이미지 인식 컨테스트 ILSVRC에서 딥러닝 모델이 1위
- 2012 구글의 딥러닝 기반 인공지능이 유튜브에서 고양이를 인식
- 2014 애플의 시리 음성인식 시스템이 딥러닝을 이용하도록 변경
- 2016 알파고
- 2016 아우디, BMV 자동 운전기술에 딥러닝 적용

