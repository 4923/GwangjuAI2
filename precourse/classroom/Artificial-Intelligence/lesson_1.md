# AI 1강 : 기초

### 역사
1.  
존 매카시가 개최한 일명 다트머스 회의(Dartmouth workshop)에서 마빈 민스키, 너대니얼 로체스터, 클로드 섀넌 등이 인공지능이라는 용어가 처음 제안하였다.  
다트머스 회의는 1956년 8월 31일 미국 다트머스 대학교에서 8주간에 걸쳐 열렸는데 주된 토의 방식은 브레인 스토밍이었다.  
이 회의를 통해 '다트머스 인공지능 여름 연구 프로젝트(Dartmouth Summer Research Project on Artificial Intelligence)'가 시작되었으며, 인공지능이라는 분야가 공식적으로 출범하게 된다.

2.  
1854년 영국의 수학교사 조지 불 (George Boole)은 불 논리(Boolean logic)를 창시한 사람이다.
불 논리를 이용하면 현실세계의 불확실성을 0과 1, 또는 참과 거짓으로 구분할 수 있다.
이 논리를 담은 대수형식의 수학적 토대를 담은 '사고의 법칙에 대한 탐구'라는 책을 발표한다.
조지 불은 확률론에도 상당한 기여를 했는데, 이 확률론은 머신러닝의 토대가 된다.
또, 조지 불은 역전파(backpropagation)기술을 고안해낸 제프리 힌턴의 조상이기도 하다.

- 역전파  
    머신러닝에서는 인공신경망을 이용해 예측값과 실제값의 오차를 최소화 하기 위해 경사하강법을 사용한다.
    이때 입력층에서 출력층으로 이동하며 가중치를 계산하는 방식이 순전파이며  
    출력층에서 입력층으로 이동하며 가중치를 계산하는 방식을 역전파라고 한다.

3. 
인공지능 발전은 인간이 일반적으로 수행하는 지적 작업을 자동화하려는 노력이다.

- 하드코딩
    + 사전에 입력한 규칙만을 따르는 프로그램 => 인공지능이 아니다.
- 기호주의 인공지능
    + 1950 ~ 1980 지배적 패러다임
    + 인간의 모든 지식을 기호화하고, 이 관계를 모두 컴퓨터에 학습시킨다.
    + 장점 : 잘 정의되고 논리적인 문제를 해결하는데 적합하다.
    + 단점 : 이미지 분류, 음성 인식, 번역 등 복잡하면서도 모호한 문제는 해결할 수 없다.

- 1960년대 연구가 잘 진행되지 않았던 이유
    1. 부족한 예산
    2. 과도한 목표
    3. 부족한 의사소통
    4. 하드웨어의 한계 -> 2020년에 TPU가 등장하며 극복됨
        - TPU?
            + Tensor Processing Unit
            + 2020년 구글에서 개발한 머신러닝 전용 하드웨어
            + 선형대수의 연산을 가속화 -> 신경망 모델 학습시간 단축

- 언어 번역과 인공지능   
    빠르게 발전하는 딥러닝의 수혜를 가장 많이 받는 분야로, 인공지능의 성배라고 불리는 영역이다.
    - 과거 : 함께 번역될 수 있는 단어의 조합
        + 예) I am robot = 나는 이다. 로봇 = 나는 로봇이다.
    - 현재 : 딥러닝으로, 전체 문장들 사이의 상관성을 탐색

- 음성인식과 인공지능  
    MS사는 2012년도 부터 발전을 이룩하기 시작해 16년도에 "120개 계층으로 이루어진 딥러닝 네트워크를 통해 말하는 살마이 다수인 상황에서도 인간수준의 수행력을 성취" 하는 발전을 이뤄냄
    