{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Metrics\n",
    "\n",
    "- 문제에 맞게 거리함수를 사용해야한다.  \n",
    "- 각각의 거리 함수가 어떨 때 쓰이는지 알아야 한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 종류\n",
    "1. Euclidean distance (L2)\n",
    "2. Manhattan distance (L1)\n",
    "3. Cosine similarity & distance\n",
    "\n",
    "수학에서 사용하는 L1, L2와 같으므로 수식 정리를 위해 주피터 노트북을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `[recap]` L1, L2 Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norm은 벡터의 크기 (magnitude), 길이 (length)를 표현하는 용어다. 그 종류로는 $L_{1}$, $L_{2}$, $L_{\\infty}$ 등이 있는데 이 때 사용하는 용어가 규제 (regression) 와 거리함수 (distance metrics) 에서 동일한 의미로 사용된다.\n",
    "\n",
    "- regression : 과대적합을 해결하기 위한 방법* 중 하나로 정규화, 규제로 번역되나 일반적으로 규제라고 표현한다. 다중선형회귀에서 $\\vec{w}$값이 지나치게 커지거나 작아지는 것을 방지하기 위해 $\\vec{w}$ 값의 범위를 지정하여 최대, 최소값을 *규제*하기 때문이다.\n",
    "    - *과대적합을 해결하기 위한 방법 : 데이터의 개수 늘리기, 규제, cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 $p$값에 무엇이 들어가는지가 norm의 종류를 결정한다.\n",
    "- $p$는 norm의 차수, n은 대상 벡터의 요소 수\n",
    "\n",
    "$$\\vert\\vert{x}\\vert\\vert_{p}\n",
    "=   (\n",
    "    \\sum_{i=1}^{n}\n",
    "    \\vert x_{i} \\vert ^{p}\n",
    "    )\n",
    "    ^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "1. $L_{1}$\n",
    "    - **요소의 절댓값 크기의 합**\n",
    "    - p=1\n",
    "    - 축에 평행하게 이동하는 경로\n",
    "    - 벡터의 크기 (magnitude)\n",
    "        - 원점에서 좌표까지의 거리\n",
    "    - 맨해튼거리\n",
    "    - 요소의 값 변화를 정확하게 파악할 수 있다.\n",
    "    - computer vision에서 주로 사용\n",
    "\n",
    "2. $L_{2}$\n",
    "    - p=2\n",
    "    - 직선의 최단거리\n",
    "        - **해당 차원의 좌표평면에서의 원점부터 좌표까지의 최단거리**\n",
    "    - 유클리드 공간에서 계산하므로 euclidean norm이라고도 함\n",
    "    - 2차원에서의 $L_{2}$ norm은 피타고라스 정리와 동일\n",
    "    - KNN, Kmean 알고리즘에서 사용\n",
    "\n",
    "3. $L_{\\infty}$\n",
    "    - p가 무한대일 때\n",
    "    - 상한 노름, maximum norm이라고 말함\n",
    "    - 벡터 성분의 최댓값을 구한다.\n",
    "\n",
    "\n",
    "[참고](http://taewan.kim/post/norm/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance (L2)\n",
    "\n",
    "> 유클리드 공간 안의 두 점의 거리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$d(x,y) = \\sqrt{\\sum_{i=1}^{n}(x_{i} - y_{i})^2}$$\n",
    "\n",
    "- 문제/한계\n",
    "    1. 원소의 차가 **제곱**이 되므로 이상치 **outlier에 민감**\n",
    "    2. $\\therefore$ 이상치가 포함된 특정 차원이 결과값에 크게 영향을 미칠 수 있다.\n",
    "    - 예시 : [MIT/Introduction to ML/37:14](https://youtu.be/h0e2HAPTGF4?t=2230)\n",
    "        - *악어*, 뱀, 개구리가 있을 때 악어와 뱀은 파충류, 개구리는 양서류다. 이 때 *악어는 뱀에 가까운가 개구리에 가까운가?*\n",
    "            - 우리는 이미 답을 알고 있다. 악어는 계통학적으로 같은 파충류인 뱀에 더 가깝다.\n",
    "        - 그러나, 비슷한 정도를 유클리드 거리로 판단하면, 다리의 개수 차원에서 개구리는 악어에 더 가까워진다. (다리의 개수가 모두 4개이므로)\n",
    "            - 강의의 표 확인\n",
    "                - 개구리와 악어 사이의 거리 : 1.7\n",
    "                - 악어와 뱀 사이의 거리 : 4.123\n",
    "        - 따라서 leg 차원의 영향력이 너무 커지므로 악어는 뱀이 아닌 개구리에 더 가깝다는 오답이 산출된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan distance (L1)\n",
    "\n",
    "> A.K.A Taxicab distance, Cityblock distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ d = \\sum_{i=1}^{n} \\vert {x_{i} - y_{i}} \\vert $$\n",
    "\n",
    "- 사용하는 상황\n",
    "    - 고차원 벡터의 거리를 구할 때 일반적으로 많이 사용한다. (L2거리보다 낫다)\n",
    "        - 차원이 커질수록 이상치가 나타날 확률이 커지는데, 이에 대응하기 쉽다.\n",
    "    - outlier에 크게 영향을 받지 않는다. (특정 차원의 영향력을 줄일 수 있다.)\n",
    "- 문제/한계?\n",
    "    - outlier에 강한게 문제가 될 수 있다.\n",
    "        - e.g. **TF-IDF**는 원래 이상치를 만드는 작업이기 때문에 이런 이상치를 제거하는 과정은 예측에 악영향을 끼친다.\n",
    "- $\\therefore$ Count-based Matrix에서는 Euclide distance가 더 효과적이다.\n",
    "    - 왜냐하면\n",
    "    1. 대부분의 특성이 0에 가까운 희소행렬은 차원의 저주를 받는다.(e.g. count-based matrix : DTM, TF-IDF) \n",
    "    2. 이 때의 키워드 값은 이상치로 분류될 가능성이 높은데 이 이상치를 **강조** 하는것이 해당 행렬이다. \n",
    "    3. 그런데 Manhattan distance는 (정규분포 기준) 이상치를 억누르는 성질이 있으므로 count-based matrix에서는 적합하지 않다.\n",
    "        - 안그래도 희소한 행렬에서 manhattan distance를 구해져버리면 의미가 더 옅어진다.\n",
    "        - **\"일반적인\"\"** 상황이 무엇인지 잘 정의할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity & Cosine Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성질\n",
    "    - -1과 1사이로 정규화 된다.\n",
    "    - 벡터의 내적 공식을 변형하여, 벡터의 크기는 무시하고 **각도**만을 고려한다.\n",
    "        - 문서들의 길이 편차가 큰 경우 유용하다.\n",
    "    - $Cosine\\ Distance = 1 - Cosine\\ Similarity$\n",
    "        - $\\because$ 거리는 반드시 0 이상 (nonnegative)이다.\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "| 방향 | 코사인 유사도|\n",
    "| :-: | :-: |\n",
    "| 방향이 반대일 때 | -1 |\n",
    "| 직교할 때 | 0 | \n",
    "| 평행할 때 | 1 |\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
