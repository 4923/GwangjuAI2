# TFIDF
### Idea
1. DTM 의 단점에서 무식하게 많이 등장한다고 중요한 단어는 아니라는걸 알았다.  
2. 그렇다면 중요한 단어는 어떻게 알 수 있을까? -> 빈도는 어떨까?
3. + 사실 그냥 불용어만 제거해도 DTM의 일시적인 단점은 해결될 것 같으나 근본적인 해결책은 아닌 것 같다. 

### Purpose
말뭉치(corpus)에서 단어의 중요도를 상대적으로 파악하고 각 문서(document)를 대변할 수 있는 단어를 찾겠다.
=> 키워드를 찾기 위함. 중요한 단어에 가중치를 부여하고 중요하지 않은 단어를 구분할 때 사용한다.

### TF * IDF
$$TFIDF (t, d) = TF(t, d) * IDF(t)$$

1. TF(term, document) : 문서에서 <u>용어가 몇 번 사용</u>되었는가?
    - focused on documents
    - DTM과 같다. 각 문서에서 쓰인 단어의 개수를 세고, 문서를 그 결과로 변환한다.

2. IDF = Inversed DF(term) : 용어가 등장한 <u>문서가 몇 개</u>인가?
    1. DF
        - focused on terms
        - 용어가 등장하는 문서의 개수를 파악하여 **말뭉치에서 용어의 사용 횟수**를 파악한다. (개별 문서에서의 등장 횟수는 고려 대상이 아니다.)
        - DF가 크면 해당 단어를 사용하는 문장이 많다.
        - DF와 **반비례!!!** 한다.
    2. IDF : term에 대한 일종의 가중치?
        - DF에 역함수를 취했으므로 IDF가 높으면 말뭉치 전체에서 용어가 사용되는 빈도가 낮다.
        - **왜?** : 불용어를 생각해보자. 문서 전체에서 사용되는 빈도가 높은건 **문장의 필수 구성요소일 가능성이 높다**는 뜻이다. 아무리 특정 단어가 많이 사용돼도 문장의 필수 구성요소보다는 덜 사용되지 않을까? 
        ### $\therefore$ 사용되는 빈도가 낮을 수록 문서를 대표하는 단어일 가능성이 높다는 가설 수립 가능 (only 가능성)
        $$IDF(t) = \log(\frac{n}{1 + DF(t)})$$
        - 왜 $\frac{1}{DF(t)}$ 가 아니냐?
            1. 1을 더하지 않으면 DF(t)가 0인 경우 0으로 나누게 되는 문제 (**zero division**) 발생 : 분모에 +1을 추가
            2. log를 취하지 않으면 흔하지 않은 단어의 가중치가/중요도가 지나치게 커진다. : log를 취해 scale 조정, **값의 편차를 줄이기 위해**

3. TFIDF : 말뭉치 전체에서는 차지하는 비중은 작으나 특정 문서에서 많이 사용되었다면? 문서를 대표하는 문장일것이다. (가설)
    - 어떻게? : DTM에 IDF를 곱하여(**가중치를 주어**) 중요한 문장을 골라낸다.

    - 장점: 
        - 문서를 대표하는 단어를 찾을 수 있다. (확률적으로)
        - 연어 collocation를 추출할 수 있다. -> 왜였더라 d를 관용구, t를 단어로 취급하면 연어를 골라낼 수 있는데
            - 문장의 패턴을 찾을 수 있으므로 (문장구조를 지탱하는 단어처럼 반복되는 패턴은 TFIDF 점수가 낮으므로 다양한 변주가 가미된 관용어구들을 학습 데이터로 입력하면 함께 쓰이는 단어들만 (마찬가지로 불용어는 무시) 골라낼 수 있다.
            - 직관적으로는 이해하겠는데 세세한 부분까지 확신하기는 어렵네 이게 맞나

    - 단점: 
        - 동음이의어 구분 불가
            - 02_DTM 시작할 때 맥락에서 단어의 뜻을 알아낸다고 적어놨지만 어쩔 수 없이 rule base model에서는 동음이의어를 구분하기 어렵다.