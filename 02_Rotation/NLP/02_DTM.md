# DTM
> Document Term Matrix

문서를 용어를 기준으로 수치화 한 결과

## 왜?
NLP의 목적을 상기한다.  
자연어처리는 기계가 인간의 언어를 이해할 수 있도록 하는 작업으로 이를 위해서는 각 단어를 새로운 방식으로 **표현**하는 과정을 거쳐야 한다.  
단어를 표현하는 방법에는 one hot vector도 있는데 이런 방식은 단어의 뜻을 담을 수 없기 때문에 위 목적에 부적합하다.  
$\therefore$ 단어의 의미를 담을 수 있는 표현 방법을 찾아야 한다.

## 그렇다면 단어의 뜻은 어떻게 해야 담을 수 있을까?
먼저, 단어는 어떻게 뜻을 가지게 되는가? 단어의 정의는 인간이 임의로 지정한다. 하지만 같은 형태를 한 단어라면? 이 경우에 우리는 **문맥을 읽는다.** 문맥을 읽는다는 것은 단어가 사용된 문장에서 해당 단어의 뜻을 유추한다는 것으로, 이런 방식은 기계가 모방할 수 있다.   
( $\because$ 세상에 존재하는 모든 단어를 rule로 만들어 기계에게 주입할 수는 없지만 문맥에는 패턴이 있기 때문이다. )

이상의 전제를 **distributional hypothesis** 라고 한다.  
$=$ '단어의 뜻은 문장에 분배되어 있다' 또는 '비슷한 맥락에서 쓰이는 단어들은 유사한 의미를 갖는다'는 뜻이다.

## DTM은?
DTM은 위 가설에 기반하여 각 문장을 단어 기반으로 분석한다.  
이에 더해 자주 쓰이는 단어는 문장 안에서 중요한 위치를 차지한다는 가설을 추가하여 문서(Document)에서 쓰인 모든 단어(Term)를 구한다. 그리고 각 문장을 그 **단어가 쓰인 빈도를 나타내는 벡터로 변환**하여 하나의 문서를 행렬 (Matrix)으로 표현한다. 그렇게 되면 각 문장간의 코사인 유사도 cosine similarity 를 구하여 문장간의 **유사도**를 산출할 수 있다.

1. **장점**
    - 단어의 의미를 반영한 표현방식이므로 문장간 유사도를 알아낼 수 있다. : **cosine similarity**
    - one hot vector의 단점인 희소행렬 문제를 어느정도 해결할 수 있다.
2. **단점**
    - 단순히 **빈도**만 따지기 때문에
        - 불용어를 걸러내지 못한다. (관사, 전치사 등 의미없이 자주 쓰이는 요소를 중요한 단어로 인식한다.)
        - 어순을 반영하지는 못한다.
3. 장점인지 단점인지 모르겠는 특징
    - 코사인 유사도는 **각도**를 확인하는 작업으로 벡터의 크기는 고려하지 않는다. 다시 말해, 한 문장 안에서 **모든 단어가 동일한 비율로 가감된다면** 두 문장을 같은 문장으로 인식한다.
        - e.g. 
            - A: 'I feel tired'
            - B: 'I feel tired I feel tired'
            - 두 문장을 같은 문장으로 인식한다. (코사인 유사도가 1이다.)