{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Regularization \r\n",
    "- L1 (Lasso)\r\n",
    "- L2 (Ridge)\r\n",
    "- ElasticNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "선형회귀 모델을 개선하는 방안으로 overfitting을 방지하거나 완화하기 위해 사용된다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Quick recap**\r\n",
    "\r\n",
    "- Linear Regression\r\n",
    "    - 단순 선형회귀 : 하나의 특성 (feature, 독립변수) 으로 결과값 (label, target, 종속변수)을 예측하는 회귀\r\n",
    "    - 다중 선형회귀 : 여러개의 특성으로 결과값을 예측하는 회귀\r\n",
    "\r\n",
    "- 용어\r\n",
    "    - 독립변수 : 다른 변수에 영향을 주는 값\r\n",
    "        - = 특성, x 값, feature\r\n",
    "    - 종속변수 : 독립변수에 영향을 받는 값\r\n",
    "        - 주로 결과값, label, target\r\n",
    "    - 회귀계수 : 절편과 기울기\r\n",
    "        - `model.coef_` 함수로 회귀계수를 구할 수 있다.\r\n",
    "    - 다중 공선성 multicollinearity : 독립변수들 간의 강한 상관관계로 인해 회귀분석의 결과를 신뢰할 수 없게 되는 현상\r\n",
    "        - 해결\r\n",
    "            - 상관계수 분석으로 제거한다\r\n",
    "            - 요인 등을 분석하여 차원을 축소한다\r\n",
    "    - RSS : 회귀분석에서 비용함수를 RSS 라고 한다.\r\n",
    "    - 최소제곱법 : 회귀계수 (w와 b) 를 구하기 위해 측정된 값을 기초로 제곱합을 만들고 그 값을 최소로 하는 방법\r\n",
    "        - $\\because$ 선형회귀의 기본 가설은 일차함수의 직선 방정식\r\n",
    "    \r\n",
    "- 선형회귀의 문제점\r\n",
    "    - 다중 선형 회귀에서는 특성값과 라벨값 (X와 y, 독립과 종속) 사이의 관계를 불필요하게 자세하게 분석했을 때 과적합이 발생함\r\n",
    "    - 과적합이 발생한다는 것은 새로운 데이터가 주어졌을 때 정확히 예측하기가 어렵다는 것으로, 일반화 능력이 떨어진다는 말과 동일함\r\n",
    "        - train score는 높지만 test score가 낮을 때 (10~20이상)\r\n",
    "    - 이를 해결하기 위해 생긴 기법이 **규제 모델**이다.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 규제모델 일반"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. 특성이 증가하면 모델의 복잡성이 증가한다.\r\n",
    "2. 모델의 복잡성이 증가하면 Variance/분산은 증가하고 bias/편향이 감소한다.\r\n",
    "    - 항목 2의 상황을 overfitting, 과대적합이라 말한다.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*왜 variable과 bias라고 하나?*\r\n",
    "\r\n",
    "회귀변수의 예측을 위해 모델은 여러 값을 산출하는데 이 값을 표현하기 위해 값의 분포를 나타내는 분산과 편향을 사용한다.\r\n",
    "\r\n",
    "- variable : 값들끼리 멀리 떨어져 있을 때\r\n",
    "- bias : 정답과 대체로 멀리 떨어져 있을 때\r\n",
    "\r\n",
    "![var, bias](https://lh3.googleusercontent.com/K3fjd0dVZbfXCo5LHFZVfSdfq5UBM-iLniMQZ3V4TqByZON9LvmtYazglVlcN9kyVXc5ZpZT2BJhd_yLWzZ8kcYku8yyEn2PaHdEn-JBobtPcWWG26WVUXdClvTf_o9nv835wghYCoY)\r\n",
    "- 출처 : https://opentutorials.org/module/3653/22071\r\n",
    "\r\n",
    "> 목표 : Variable, bias 두 값의 적절한 중간점을 찾아야 한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L2 : Ridge Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> 평균제곱오차 Mean Square Error에 $alpha$ 항을 추가한다.\r\n",
    "\r\n",
    "- <font color=orange>(규제모델 공통) $alpha$ : 데이터의 학습적합도와 회귀계수 w의 크기를 제어하는 계수</font>\r\n",
    "\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{aligned}\r\n",
    "cost(W,b) &=MSE+regularization\\ variance\\\\ \r\n",
    "&=MSE+\\alpha \\cdot { L }_{ 2 }norm\\\\ \r\n",
    "&=\\cfrac { 1 }{ m } \\sum\\limits _{ i=1 }^{ m }{ (H({ x }^{ (i) })-{ y }^{ (i) }) } ^{ 2 }+\\alpha \\sum\\limits _{ j=1 }^{ n }{ { w }_{ j }^{ 2 } } \\\\\r\n",
    "& (n: number\\ of\\ weights\\ , α:\\ regularization)\r\n",
    "\r\n",
    "\\end{aligned}\r\n",
    "$$\r\n",
    "\r\n",
    "- 효과\r\n",
    "    - $w$에 규제하는 $alpha$ 값을 곱한 것이기 때문에 $alpha$와 $w$는 반비례 관계다.\r\n",
    "    - $\\therefore$, \r\n",
    "        - $alpha$가 커지면 반비례 관계인 $w$는 작아지고\r\n",
    "            - $alpha$가 너무 커지면 정확도가 감소하여 과소적합될 위험이 있다.\r\n",
    "        - $alpha$가 작아지면 반비례 관계인 $w$가 커진다. \r\n",
    "            - $w$가 커지더라도 $alpha$ 값이 과도하게 회귀계수 $w$가 커지는 것을 제한하기 때문에 과적합이 완화된다.\r\n",
    "            - $alpha$가 너무 작아져 0이 되면 MSE가 되기 때문에 선형 회귀 모델이 된다.\r\n",
    "\r\n",
    "> Ridge 모델은 <font  color=orange>bias을 약간 손해보면서 variance를 크게 줄여</font> 성능의 향상을 꾀한다.  \r\n",
    "> 단점 : <font  color=orange>몇몇 변수가 중요하더라도 모든 변수에 대해 적합을 해야 하고 완벽한 0은 나오지 않는다.</font> -> 예측의 문제가 아니라 해석의 문제\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L1 : Lasso Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "\r\n",
    "- Ridge regression의 단점을 해결하기 위한 방법\r\n",
    "- 학습한 가중치의 절대값을 규제항으로 사용한다 : 가중치의 절대값을 사용한다.\r\n",
    "\r\n",
    "$$  \r\n",
    "\\begin{align} \r\n",
    "cost(W,b)   \\\\ \r\n",
    "& =MSE+regularization\\ variable \\\\  \r\n",
    "& =MSE+\\alpha \\cdot { L }_{ 1 }norm \\\\  \r\n",
    "& =\\cfrac { 1 }{ m } \\sum\\limits_{ i=1 }^{ m }{ (H({ x }^{ (i) })-{ y }^{ (i) }) } ^{ 2 }+\\alpha \\sum\\limits_{ j=1 }^{ n }{ \\left| { w }_{ j } \\right|  }  \\\\\r\n",
    "& (n: number\\ of\\ weights\\ , α:\\ regularization)\r\n",
    "\\end{align} \r\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "조정을 전체 feature를 대상으로 하므로 회귀계수가 0이 될 수 있다. (미세하게 영향을 미치는 값은 중요하지 않다고 판단하여 탈락시킨다.)  \r\n",
    "이러한 feature 탈락을 자동 선택으로 표현하기도 한다.\r\n",
    "\r\n",
    "$\\therefore$ 유의미한 변수가 적을 때에는 Lasso를, 많을 때에는 Ridge가 더 좋은 성능을 보인다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ElasticNet Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- L1 Regression + L2 Regression\r\n",
    "- lasso처럼 상관관계가 높은 feature, 즉 중요한 feature만 선택하나 $L2$ 규제를 포함하여 $alpha$ 값에 따른 급격한 변화를 완화한다.\r\n",
    "- 단점\r\n",
    "    - 수행 시간이 오래 걸리며\r\n",
    "    - 튜닝이 중요하다. $\\therefore$ Ridge와 Lasso가 익숙해진 후에 사용할 것\r\n",
    "\r\n",
    "**수식**\r\n",
    "\r\n",
    "$$\r\n",
    "\\begin{align}\r\n",
    "cost(W,b)\\\\ \r\n",
    "& =MSE+regularization\\ variable\\\\\r\n",
    "& =MSE+ { \\alpha }_{ 1 }\\cdot { L }_{ 1 }norm + { \\alpha }_{ 2 }\\cdot { L }_{ 2 }norm\\\\\r\n",
    "& =\\cfrac { 1 }{ m } \\sum\\limits _{ i=1 }^{ m }{ (H({ x }^{ (i) })-{ y }^{ (i) }) } ^{ 2 } +\\alpha _{ 1 }\\sum\\limits _{ j=1 }^{ n }{ \\left| { w }_{ j } \\right|  +\\alpha _{ 2 }\\sum\\limits_{ j=1 }^{ n }{ { w }_{ j }^{ 2 } } } \\\\\r\n",
    "& (n: number\\ of\\ weights\\ , α:\\ regularization)\r\n",
    "\\end{align}\r\n",
    "$$ "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}