{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "> modeling without tensorflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 순서\r\n",
    "\r\n",
    "1. 데이터 불러오기\r\n",
    "2. 독립변수와 종속변수 분할하기\r\n",
    "3. 파라미터 생성\r\n",
    "4. 순전파 연산\r\n",
    "5. 역전파 연산\r\n",
    "6. 파라미터 갱신\r\n",
    "7. 손실함수 정의\r\n",
    "8. 평가"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Guide\r\n",
    "\r\n",
    "![model guide](img/abalone_mini_without_tf_guide.png)\r\n",
    "\r\n",
    "- main_execute()\r\n",
    "    - tf처럼 hyperparameter를 입력받도록 한다.\r\n",
    "- math utils?\r\n",
    "    - 실행시킬 때 불러올 모듈/데이터들"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# main_execute()\r\n",
    "\r\n",
    "함수의 모든 기능을 `main_execute()` 에서 관리하므로 미리 설계한다. \r\n",
    "\r\n",
    "- 당장은 동작하지 않지만 버튼 먼저 만들자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def main_execute(epoch_count = 10, mb_size = 2, report = 2, train_ratio = 0.8):\r\n",
    "    load_dataset()\r\n",
    "    weight_initial, bias_initial = init_param()\r\n",
    "    losses_mean_row, accs_mean_row, final_acc = train_and_test(epoch_count, mb_size, report, train_ratio)\r\n",
    "    \r\n",
    "    return weight_initial, bias_initial, losses_mean_row, accs_mean_row, final_acc "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`main_execute()` 에서 만든 버튼\r\n",
    "\r\n",
    "1. `load_dataset()`\r\n",
    "2. `init_param()`\r\n",
    "3. `train_and_test()`\r\n",
    "\r\n",
    "상단의 함수를 생성하자."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MathUnits.ipynb\r\n",
    "\r\n",
    "필요로 하는 파일 (csv 등) 을 ipynb로 작성한다.\r\n",
    "- 별도의 파일로 생성함 : `13_MathUnits.ipynb`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load_dataset()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def load_dataset():\r\n",
    "    # 데이터 불러오기\r\n",
    "    path = \"dataset/dataset/abalone_mini.csv\"\r\n",
    "    with open(path) as csvfile:\r\n",
    "        csvreader = csv.reader(csvfile)\r\n",
    "        next (csvfile)\r\n",
    "\r\n",
    "        rows = []\r\n",
    "        for row in csvreader:\r\n",
    "            rows.append(row)\r\n",
    "\r\n",
    "    # 자주 쓰는 variable globalization\r\n",
    "    global input_cnt, output_cnt, data\r\n",
    "    \r\n",
    "    # input_cnt, output_cnt 생성\r\n",
    "    input_cnt, output_cnt = 10, 1\r\n",
    "\r\n",
    "    # one hot vector\r\n",
    "    data = np.zeros([len(rows), input_cnt + output_cnt])    # 행은 rows의 개수, 열은 input_cnt + output_cnt\r\n",
    "\r\n",
    "    for idx, row in enumerate(rows):\r\n",
    "        # one hot vector\r\n",
    "        if row[0] == 'M': data[idx, 0] = 0\r\n",
    "        if row[0] == 'F': data[idx, 1] = 1\r\n",
    "        if row[0] == 'I': data[idx, 0] = 2\r\n",
    "\r\n",
    "        # 나머지 복사 \r\n",
    "        data[idx, 3:] = row[1:]\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load `MathUnits.ipynb`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%run 13_MathUnits.ipynb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "load_dataset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# init_param()\r\n",
    "parameter 초기화\r\n",
    "\r\n",
    "- weight, bias를 무작위 값으로 초기화한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def init_param():\r\n",
    "    # weight, bias list\r\n",
    "    weight_initial, bias_initial = [], []\r\n",
    "\r\n",
    "    # set initial value of weight, bias\r\n",
    "    weight  = np.random.normal(RND_MEAN, RND_STD, size = [ input_cnt, output_cnt ])     # 입력값과 행렬곱을 수행하기 위해 input_cnt, output_cnt로 size를 설정\r\n",
    "    bias    = np.zeros([output_cnt]) # np.zeros를 사용한다. (not normal func)\r\n",
    "    print(f\"Initial Weight Value : \\n{weight}\")\r\n",
    "    print(f\"\\nInitial Bias Value : \\n{bias}\")\r\n",
    "\r\n",
    "    # collect previous weight, bias\r\n",
    "    weight_initial.append(weight)\r\n",
    "    bias_initial.append(bias)\r\n",
    "\r\n",
    "    return (weight_initial, bias_initial)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "왜 np.zeros를 사용하나?\r\n",
    "\r\n",
    "- bias의 초기값은 큰 영향을 미치기 때문에 0으로 맞춘다 : 0으로 맞추는 것도 초기화 방식 중 하나\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "weight_initial, bias_initial = init_model()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial Weight Value : \n",
      "[[ 0.03598319]\n",
      " [ 0.01456214]\n",
      " [-0.05456479]\n",
      " [-0.06218915]\n",
      " [ 0.0222744 ]\n",
      " [ 0.03182617]\n",
      " [ 0.0325858 ]\n",
      " [-0.06482078]\n",
      " [ 0.0276185 ]\n",
      " [ 0.02679505]]\n",
      "\n",
      "Initial Bias Value : \n",
      "[0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# arrange_data()\r\n",
    "\r\n",
    "- 전체 인덱스 탐색\r\n",
    "- 데이터 뒤섞기\r\n",
    "    - np.random.shuffle(array_name)\r\n",
    "- 학습 및 테스트의 분할 인덱스 탐색\r\n",
    "- 미니배치의 수 탐색 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def arrange_data(mb_size, train_ratio):\r\n",
    "    # 자주 사용하는 데이터 전역변수화\r\n",
    "    global shuffle_map, test_begin_index\r\n",
    "\r\n",
    "    shuffle_map = np.arange(data.shape[0])\r\n",
    "    np.random.shuffle(shuffle_map)     # shuffle_map은 단순히 array를 생성한 값이니 이를 섞어 사용한다.\r\n",
    "\r\n",
    "    mini_batch_step_count = int(data.shape[0] * train_ratio // mb_size)     # 학습 데이터의 개수 // mb_size == 전체 개수의 mini_batch의 개수\r\n",
    "    test_begin_index = mini_batch_step_count * mb_size # 전체 학습 데이터의 개수 == 테스트 데이터화 학습 데이터의 경계\r\n",
    "\r\n",
    "    return mini_batch_step_count    # 상대적으로 잘 쓰지 않으므로 전역변수화가 아닌 return 값으로 설정\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 함수 test \r\n",
    "mini_batch_step_count = arrange_data(mb_size=2, train_ratio=0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(f\"mini_batch_step_count : {mini_batch_step_count}\")\r\n",
    "print(f\"shuffle_map : {shuffle_map[:3]}\")   # 돌릴 때 마다 매번 바뀐다.\r\n",
    "print(f\"test_begin_index : {test_begin_index}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mini_batch_step_count : 4\n",
      "shuffle_map : [7 2 3]\n",
      "test_begin_index : 8\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_test_data()\r\n",
    "\r\n",
    "- 테스트 데이터 분할\r\n",
    "- 독립 및 종속 변수 생성"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def get_test_data():\r\n",
    "    test_data = data[shuffle_map[test_begin_index:]]\r\n",
    "    return test_data[:, :-output_cnt], test_data[:, -output_cnt:]     # 독립변수, 종속변수 분리하여 추출 : test_x, test_y`"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "test_x, test_y = get_test_data()\r\n",
    "print(test_x)\r\n",
    "print(\"---\" * 30)\r\n",
    "print(test_y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.     0.     0.     0.365  0.295  0.08   0.2555 0.097  0.043  0.1   ]\n",
      " [2.     0.     0.     0.33   0.255  0.08   0.205  0.0895 0.0395 0.055 ]]\n",
      "------------------------------------------------------------------------------------------\n",
      "[[7.]\n",
      " [7.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_train_data()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![epoch idea](img/abalone_mini_without_tf_epoch.png)\r\n",
    "\r\n",
    "- epoch이 진행될 때 마다 shuffle 된다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래처럼 처음부터 8개를 다 가져오면 안된다.  \r\n",
    "\r\n",
    " $\\because$ mini batch 단위로 학습하므로\r\n",
    "```\r\n",
    "def get_train_data():\r\n",
    "    train_data = data[shuffle_map[:test_begin_index]]      \r\n",
    "````"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\therefore$ minibatch 인덱스의 특징을 찾는다.\r\n",
    "\r\n",
    "minibatch 단위에 따라 인덱스가 달라지는 특징 발견 (0:2, 2:4, 4:6, 6:8)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# [idea]\r\n",
    "# mb_size = 2\r\n",
    "# def get_train_data():\r\n",
    "    # for idx in range((test_begin_index)):\r\n",
    "    #     train_data  = data[shuffle_map[ mb_size * idx : mb_size * (idx+1)]]        # ???????????????? 규칙은 알겠는데 왜 data[shuffle_map~ ]이 됐지?\r\n",
    "    # return (train_data[:, :-output_cnt], train_data[:, -output_cnt:])\r\n",
    "    # ---------------------- \r\n",
    "# 이 때 range는 (==n) 상위 함수에서 받는다 : 따라서 n을 parameter로 받는다. (mb_size도 마찬가지)\r\n",
    "\r\n",
    "def get_train_data(mb_size, n):\r\n",
    "    if n == 0:\r\n",
    "        np.random.shuffle(shuffle_map[: test_begin_index])  # 돌아갈 때 마다 학습데이터 부분만 섞어라.\r\n",
    "    \r\n",
    "    train_data = data[shuffle_map[mb_size*n: mb_size * (n+1)]]\r\n",
    "    return (train_data[:, :-output_cnt], train_data[:, -output_cnt:])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "train_x, train_y = get_train_data(mb_size = 2, n = 0)\r\n",
    "\r\n",
    "print(train_x)\r\n",
    "print(\"===\" * 30)\r\n",
    "print(train_y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.     1.     0.     0.44   0.34   0.1    0.451  0.188  0.087  0.13  ]\n",
      " [0.     0.     0.     0.5    0.4    0.13   0.6645 0.258  0.133  0.24  ]]\n",
      "==========================================================================================\n",
      "[[10.]\n",
      " [12.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# run_train()\r\n",
    "\r\n",
    "- 우선 틀만 생성한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def run_train(x, y):\r\n",
    "    loss = 0 \r\n",
    "    accuracy = 100\r\n",
    "    return (loss, accuracy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "run_train(0, 0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# run_test()\r\n",
    "\r\n",
    "- 순전파 연산 : 결과 확인\r\n",
    "- 평가 진행 : 정확도 측정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def run_test(x,y):\r\n",
    "    accuracy = 96\r\n",
    "    return accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "run_test(0,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train_and_test()\r\n",
    "\r\n",
    "- 학습 및 테스트 기능 실행\r\n",
    "- 정확도 및 손실값 저장\r\n",
    "    - 학습을 얼마나 진행할 것인가? : `main_execute()` 의 `train data ratio` 필요\r\n",
    "-"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_and_test(epoch_count, mb_size, report, train_ratio):\r\n",
    "    mini_batch_step_count = arrange_data(mb_size, train_ratio) \r\n",
    "    text_x, test_y = get_test_data()     # test data에 대한 독립과 종속을 밖으로 반환\r\n",
    "\r\n",
    "    for epoch in range(epoch_count):\r\n",
    "        # mini batch가 다 돌아야 1 epoch이므로 반복문 하나 더 추가\r\n",
    "\r\n",
    "        loss_list, accuracy_list = [], []\r\n",
    "        for n in range(mini_batch_step_count):\r\n",
    "            # 학습 데이터를 불러온다.\r\n",
    "            train_x, train_y = get_train_data(mb_size, n)      # n : 1epoch을 돌리기 위해 수행하는 mini batch의 step count\r\n",
    "            loss, accuracy = run_train(train_x, train_y)\r\n",
    "\r\n",
    "            # 데이터를 불러올 때에도 minibatch size 만큼 쪼개서 가져오고 있다.\r\n",
    "            # loss와 accuracy를 어떻게 한번에 보여주나? (like tensorflow) : 하나의 epoch에 대한 loss, acc?\r\n",
    "            # -> mini batch들의 값을 모아서 평균을 낸다. : loss_list, accuracy_list\r\n",
    "\r\n",
    "            loss_list.append(loss)\r\n",
    "            accuracy_list.append(accuracy)\r\n",
    "\r\n",
    "            ################################### 0721     \r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}