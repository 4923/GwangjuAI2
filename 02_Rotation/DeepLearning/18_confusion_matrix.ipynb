{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Confusion matrix\r\n",
    "\r\n",
    "*깃허브는 도대체 언제쯤 마크다운에서 LaTeX를 렌더링 하는 기능을 만들어 줄 것인가*\r\n",
    "\r\n",
    "- [[ref]](https://www.clickai.ai/resource/wiki/model_interpretation/confusionmatrix_kor)\r\n",
    "- [[ref2]](https://yogyui.tistory.com/entry/Confusion-Matrix-%ED%98%BC%EB%8F%99%ED%96%89%EB%A0%AC)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "## 필요성\r\n",
    "accuracy는 모델을 전부 평가할 수 있는 지표가 아니다.\r\n",
    "- 왜? 정확도가 높았는데도 학습이 제대로 되지 않은 상황이 있었음.\r\n",
    "\r\n",
    "이를 해소하기 위한 방법으로 정밀도 precision 와 재현율 recall을 사용한다. \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "## 혼동행렬\r\n",
    "\r\n",
    "> 특정 분류 모델의 성능을 평가하는 지표로, 실제값과 모델의 예측값을 한 눈에 알아볼수 있게 배열한 행렬이다. \r\n",
    "\r\n",
    "모델의 학습 결과는 네가지로 나눌 수 있다.\r\n",
    "-|실제값: 참 | 실제값: 거짓\r\n",
    "-|-|-\r\n",
    "예측값: 참| True Positive | False Positive\r\n",
    "예측값: 거짓| True Negative | False Negative\r\n",
    "\r\n",
    "- 실제 값을 제대로 맞추었다면 True이고 틀렸다면 False다.\r\n",
    "- 맞춘 값이 True라면 Positive이고 False라면 Negative다.\r\n",
    "- e.g. 예측값이 True이라면 Positive인데 틀렸다면 False가 붙는다. (Fale Positive)\r\n",
    "\r\n",
    "이렇게 실제값과 예측값을 표로 분류한 것을 혼동행렬이라고 하며,  \r\n",
    "**예측값이 실제값을 얼마나 정확하게 예측했는지 확인하기 위해 사용한다.**\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 정확도\r\n",
    "\r\n",
    "$$Accuracy = \\frac{True\\ Positive\\ +\\ True\\ Negative}{TP + TN + FP + FN}$$\r\n",
    "\r\n",
    "지금까지 사용했던 평가지표다. **모델이 입력된 데이터에 대해 얼마나 정확하게 예측했는지**를 나타낸다.  \r\n",
    "성공한 예측의 개수를 모든 예측으로 나눈 값이므로 예측에 성공한 값 만을 관심의 대상으로 삼는다.\r\n",
    "\r\n",
    "문제\r\n",
    "- 잘했다는건 알겠는데 뭘 얼마나 잘 예측했는지는 알 수 없다는 문제가 있다.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 정밀도 : 모델의 관점 (기준이 모델의 예측값이다)\r\n",
    "\r\n",
    "$$ Precision = \\frac{TP}{TP+FP} $$\r\n",
    "\r\n",
    "정답이 **True** 인 경우만 고려한다. 참 값을 얼마나 잘 예측했는지 알 수 있다.  \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 재현율 : 데이터의 관점 (기준이 데이터의 실제 값이다.)\r\n",
    "\r\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\r\n",
    "\r\n",
    "모든 참 값을 가진 데이터들 중에서 실제로 참임을 맞춘 예측의 비율\r\n",
    "- e.g. 실제 암에 걸린 사람이 병원에 갔을 때 암환자라고 예측될 확률"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## F1 점수\r\n",
    "\r\n",
    "$$F1\\ score\\ = 2 * \\frac{Precision * Recall}{Precision+Recall}$$\r\n",
    "\r\n",
    "정밀도와 재현율 모두 중요하니 **조화평균**을 내서 하나의 수치로 나타낸다.  \r\n",
    "모델의 예측 성능을 수치화 한결과로 값은 0과 1 사이의 값이 된다.  \r\n",
    "정밀도와 재현율 둘 다 좋을 경우에 F1 점수는 1에 가까워진다."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}